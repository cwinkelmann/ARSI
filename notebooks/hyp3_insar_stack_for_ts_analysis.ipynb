{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20494ef",
   "metadata": {},
   "source": [
    "# Time series analysis with HyP3 and MintPy\n",
    "\n",
    "This notebook walks through performing a time-series analysis of the 2019 Ridgecrest, CA earthquake with On Demand InSAR products from the Alaska Satellite facility and MintPy. We'll:\n",
    "\n",
    "1. Use the [ASF Search Python package](https://docs.asf.alaska.edu/asf_search/basics/) to:\n",
    "   - Search ASF's catalog for Sentinel-1 SAR products covering the [Ridgecrest earthquake](https://earthquake.usgs.gov/storymap/index-ridgecrest.html)\n",
    "   - Select a reference scene to generate a baseline stack\n",
    "   - Select a [short baseline subset (SBAS)](https://docs.asf.alaska.edu/vertex/sbas/) of scene pairs for InSAR processing\n",
    "\n",
    "\n",
    "2. Use the [HyP3 Python SDK](https://hyp3-docs.asf.alaska.edu/using/sdk/) to:\n",
    "   - Request On Demand InSAR products from ASF HyP3\n",
    "   - Download the InSAR products when they are done processing\n",
    "\n",
    "\n",
    "3. Use [GDAL](https://gdal.org/api/index.html#python-api) and [MintPy](https://mintpy.readthedocs.io/en/latest/) to:\n",
    "   - Prepare the InSAR products for MintPy\n",
    "   - perform a time-series analysis with MintPy\n",
    "   \n",
    "---\n",
    "\n",
    "**Note:** This notebook does assume you have some familiarity with InSAR processing with MintPy already, and is a minimal example without much context or explanations. If you're new to InSAR and MintPy, I suggest checking out:\n",
    "* our [InSAR on Demand Story Map](https://storymaps.arcgis.com/stories/68a8a3253900411185ae9eb6bb5283d3)\n",
    "\n",
    "\n",
    "* [OpenSARlab's](https://opensarlab-docs.asf.alaska.edu/) highly detailed walkthrough of using HyP3 + MintPy via these notebooks:\n",
    "  * [Prepare a HyP3 InSAR Stack for MintPy](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/Prepare_HyP3_InSAR_Stack_for_MintPy.ipynb)\n",
    "  * [MintPy Time-series Analysis](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/MintPy_Time_Series_From_Prepared_Data_Stack.ipynb)\n",
    "  \n",
    "    Note: While these notebooks make some assumptions you're working in OpenSARlab, you can run these \n",
    "    notebooks outside OpenSARlab by creating [this conda environment](https://github.com/ASFOpenSARlab/opensarlab-envs/blob/main/Environment_Configs/insar_analysis_env.yml)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6e353",
   "metadata": {},
   "source": [
    "## 0. Initial Setup\n",
    "\n",
    "To run this notebook, you'll need a conda environment with the required dependencies. You can set up a new environment (recommended) and run the jupyter server like:\n",
    "```shell\n",
    "conda create -n hyp3-mintpy python=3.10 asf_search hyp3_sdk \"mintpy>=1.5.2\" pandas jupyter ipympl\n",
    "\n",
    "conda activate hyp3-mintpy\n",
    "jupyter notebook hyp3_insar_stack_for_ts_analysis.ipynb\n",
    "```\n",
    "Or, install these dependencies into your own environment:\n",
    "```shell\n",
    "conda install hyp3-mintpy python=3.10 asf_search hyp3_sdk \"mintpy>=1.5.2\" pandas jupyter ipympl\n",
    "\n",
    "jupyter notebook hyp3_insar_stack_for_ts_analysis.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691ab533-1203-49dd-a4c8-539ce48e37f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mintpy\n",
      "  Downloading mintpy-1.5.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting argcomplete (from mintpy)\n",
      "  Downloading argcomplete-3.2.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting cartopy (from mintpy)\n",
      "  Downloading Cartopy-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting cvxopt (from mintpy)\n",
      "  Downloading cvxopt-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: dask>=1.0 in /opt/conda/lib/python3.11/site-packages (from mintpy) (2024.2.0)\n",
      "Collecting dask-jobqueue>=0.3 (from mintpy)\n",
      "  Downloading dask_jobqueue-0.8.3-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.11/site-packages (from mintpy) (3.10.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from mintpy) (1.3.2)\n",
      "Collecting lxml (from mintpy)\n",
      "  Downloading lxml-5.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from mintpy) (3.8.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from mintpy) (1.24.4)\n",
      "Collecting pre-commit (from mintpy)\n",
      "  Downloading pre_commit-3.6.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyaps3>=0.3 (from mintpy)\n",
      "  Downloading pyaps3-0.3.2-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting pykml>=0.2 (from mintpy)\n",
      "  Downloading pykml-0.2.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyproj in /opt/conda/lib/python3.11/site-packages (from mintpy) (3.6.1)\n",
      "Collecting pyresample (from mintpy)\n",
      "  Downloading pyresample-1.28.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting pysolid (from mintpy)\n",
      "  Downloading pysolid-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting rich (from mintpy)\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from mintpy) (68.2.2)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.11/site-packages (from mintpy) (0.22.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from mintpy) (1.11.4)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.11/site-packages (from mintpy) (2.0.3)\n",
      "Collecting utm (from mintpy)\n",
      "  Downloading utm-0.7.0.tar.gz (8.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click>=8.1 in /opt/conda/lib/python3.11/site-packages (from dask>=1.0->mintpy) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from dask>=1.0->mintpy) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.11/site-packages (from dask>=1.0->mintpy) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from dask>=1.0->mintpy) (23.2)\n",
      "Requirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from dask>=1.0->mintpy) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.11/site-packages (from dask>=1.0->mintpy) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from dask>=1.0->mintpy) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.11/site-packages (from dask>=1.0->mintpy) (6.8.0)\n",
      "Requirement already satisfied: distributed>=2022.02.0 in /opt/conda/lib/python3.11/site-packages (from dask-jobqueue>=0.3->mintpy) (2024.2.0)\n",
      "Collecting cdsapi (from pyaps3>=0.3->mintpy)\n",
      "  Downloading cdsapi-0.6.1.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pygrib (from pyaps3>=0.3->mintpy)\n",
      "  Downloading pygrib-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.11/site-packages (from pyaps3>=0.3->mintpy) (2.0.7)\n",
      "Collecting pyshp>=2.1 (from cartopy->mintpy)\n",
      "  Downloading pyshp-2.3.1-py2.py3-none-any.whl.metadata (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->mintpy) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib->mintpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->mintpy) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->mintpy) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->mintpy) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->mintpy) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib->mintpy) (2.8.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from pyproj->mintpy) (2024.2.2)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit->mintpy)\n",
      "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit->mintpy)\n",
      "  Downloading identify-2.5.35-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit->mintpy)\n",
      "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit->mintpy)\n",
      "  Downloading virtualenv-20.25.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting configobj (from pyresample->mintpy)\n",
      "  Downloading configobj-5.0.8-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pykdtree>=1.3.1 (from pyresample->mintpy)\n",
      "  Downloading pykdtree-1.3.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting donfig (from pyresample->mintpy)\n",
      "  Downloading donfig-0.8.1.post0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from pyresample->mintpy) (3.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->mintpy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->mintpy) (2.16.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.11/site-packages (from scikit-image->mintpy) (3.2)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.11/site-packages (from scikit-image->mintpy) (2.31.5)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.11/site-packages (from scikit-image->mintpy) (2023.9.26)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.11/site-packages (from scikit-image->mintpy) (0.3)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /opt/conda/lib/python3.11/site-packages (from distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (1.0.6)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /opt/conda/lib/python3.11/site-packages (from distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (5.9.5)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /opt/conda/lib/python3.11/site-packages (from distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (2.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /opt/conda/lib/python3.11/site-packages (from distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (6.3.3)\n",
      "Requirement already satisfied: zict>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (3.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=4.13.0->dask>=1.0->mintpy) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->mintpy) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mintpy) (1.16.0)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->mintpy)\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting filelock<4,>=3.12.2 (from virtualenv>=20.10.0->pre-commit->mintpy)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from cdsapi->pyaps3>=0.3->mintpy) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from cdsapi->pyaps3>=0.3->mintpy) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=2.10.3->distributed>=2022.02.0->dask-jobqueue>=0.3->mintpy) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.5.0->cdsapi->pyaps3>=0.3->mintpy) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.5.0->cdsapi->pyaps3>=0.3->mintpy) (3.4)\n",
      "Downloading mintpy-1.5.3-py3-none-any.whl (749 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.2/749.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dask_jobqueue-0.8.3-py2.py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyaps3-0.3.2-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading argcomplete-3.2.2-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Cartopy-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cvxopt-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pre_commit-3.6.2-py2.py3-none-any.whl (204 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.2/204.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyresample-1.28.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysolid-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Downloading identify-2.5.35-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
      "Downloading pykdtree-1.3.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (370 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.2/370.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
      "Downloading donfig-0.8.1.post0-py3-none-any.whl (24 kB)\n",
      "Downloading pygrib-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: utm, cdsapi\n",
      "  Building wheel for utm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for utm: filename=utm-0.7.0-py3-none-any.whl size=6085 sha256=ea907ffcc99b99adc98b0c6fafe726df2181d246e9c3cc8268a99d95b975c069\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/c9/30/59/0a0f4976bbec8d13eb19b8ae0d691aeb9499463fb2924bf6d8\n",
      "  Building wheel for cdsapi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cdsapi: filename=cdsapi-0.6.1-py2.py3-none-any.whl size=12008 sha256=106e9084a90599efe345a1bf2995bdd6be3841d81b79423f2c5d4a10af5de572\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/f9/26/57/a49a681496dea59363312ae87ffa8397100f8e8f6bab3591ea\n",
      "Successfully built utm cdsapi\n",
      "Installing collected packages: utm, distlib, pyshp, pykdtree, nodeenv, lxml, identify, filelock, donfig, cvxopt, configobj, cfgv, argcomplete, virtualenv, rich, pysolid, pyresample, pykml, pygrib, cdsapi, pyaps3, pre-commit, cartopy, dask-jobqueue, mintpy\n",
      "Successfully installed argcomplete-3.2.2 cartopy-0.22.0 cdsapi-0.6.1 cfgv-3.4.0 configobj-5.0.8 cvxopt-1.3.2 dask-jobqueue-0.8.3 distlib-0.3.8 donfig-0.8.1.post0 filelock-3.13.1 identify-2.5.35 lxml-5.1.0 mintpy-1.5.3 nodeenv-1.8.0 pre-commit-3.6.2 pyaps3-0.3.2 pygrib-2.1.5 pykdtree-1.3.11 pykml-0.2.0 pyresample-1.28.1 pyshp-2.3.1 pysolid-0.3.2 rich-13.7.0 utm-0.7.0 virtualenv-20.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mintpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64e566f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from dateutil.parser import parse as parse_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33543149",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fa17bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "project_name = '2019_thwaites'\n",
    "work_dir = Path.cwd() / project_name\n",
    "data_dir = work_dir / 'data'\n",
    "\n",
    "stack_start = parse_date('2019-06-10 00:00:00Z')\n",
    "stack_end = parse_date('2019-07-21 00:00:00Z')\n",
    "max_temporal_baseline = 13 #days\n",
    "\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62c544",
   "metadata": {},
   "source": [
    "## 1. Select InSAR pairs with ASF Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4498c66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASFSearchResults([<asf_search.Products.S1Product.S1Product at 0x7fe725094e50>,\n",
       "                  <asf_search.Products.S1Product.S1Product at 0x7fe7250a7250>,\n",
       "                  <asf_search.Products.S1Product.S1Product at 0x7fe7250a7710>,\n",
       "                  <asf_search.Products.S1Product.S1Product at 0x7fe7250a7bd0>,\n",
       "                  <asf_search.Products.S1Product.S1Product at 0x7fe7250b80d0>,\n",
       "                  <asf_search.Products.S1Product.S1Product at 0x7fe7250b8790>,\n",
       "                  <asf_search.Products.S1Product.S1Product at 0x7fe7250b8a90>])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import asf_search as asf\n",
    "import pandas as pd\n",
    "\n",
    "-84.01030615209014,-73.21823033315094\n",
    "# intersectsWith='POINT(-117.599330 35.769500)',\n",
    "\n",
    "search_results = asf.geo_search(\n",
    "        platform=asf.PLATFORM.SENTINEL1,\n",
    "        intersectsWith='POINT(-84.0103061 -73.218230)',\n",
    "        start='2019-06-10',\n",
    "        end='2019-07-21',\n",
    "        processingLevel=asf.PRODUCT_TYPE.SLC,\n",
    "        beamMode=asf.BEAMMODE.IW,\n",
    "        flightDirection=asf.FLIGHT_DIRECTION.ASCENDING,\n",
    "    )\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f7ccdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_results = asf.baseline_search.stack_from_product(search_results[-1])\n",
    "\n",
    "columns = list(baseline_results[0].properties.keys()) + ['geometry', ]\n",
    "data = [list(scene.properties.values()) + [scene.geometry, ] for scene in baseline_results]\n",
    "\n",
    "stack = pd.DataFrame(data, columns=columns)\n",
    "stack['startTime'] = stack.startTime.apply(parse_date)\n",
    "\n",
    "stack = stack.loc[(stack_start <= stack.startTime) & (stack.startTime <= stack_end)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8d9f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sbas_pairs = set()\n",
    "\n",
    "for reference, rt in stack.loc[::-1, ['sceneName', 'temporalBaseline']].itertuples(index=False):\n",
    "    secondaries = stack.loc[\n",
    "        (stack.sceneName != reference)\n",
    "        & (stack.temporalBaseline - rt <= max_temporal_baseline)\n",
    "        & (stack.temporalBaseline - rt > 0)\n",
    "    ]\n",
    "    for secondary in secondaries.sceneName:\n",
    "        sbas_pairs.add((reference, secondary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c5b0b",
   "metadata": {},
   "source": [
    "## 2. Request On Demand InSAR products from ASF HyP3\n",
    "\n",
    "Use your [NASA Earthdata login](https://urs.earthdata.nasa.gov/) to connect to [ASF HyP3](https://hyp3-docs.asf.alaska.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be78f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NASA Earthdata Login username:  karisuvtol\n",
      "NASA Earthdata Login password:  ········\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import hyp3_sdk as sdk\n",
    "\n",
    "hyp3 = sdk.HyP3(prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1dec3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobs = sdk.Batch()\n",
    "for reference, secondary in sbas_pairs:\n",
    "    jobs += hyp3.submit_insar_job(reference, secondary, name=project_name,\n",
    "                                  include_dem=True, include_look_vectors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22b82d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28be75c90e1345ad945c960117d6df3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [timeout in 10800 s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "jobs = hyp3.watch(jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3b3d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobs = hyp3.find_jobs(name=project_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b461cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae25a850518477f853880829a95a76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb02c85031346cd8b0f5d501f7e9923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1BA_20190628T025700_20190704T025742_HHP006_INT80_G_ueF_D268.zip:   0%|          | 0/321365565 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee09a3f27a664cefb1c356a5784ee12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1AB_20190610T025740_20190616T025659_HHP006_INT80_G_ueF_E82E.zip:   0%|          | 0/320632676 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb661d4c34c4fecac2c39cad3baf0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1BB_20190628T025700_20190710T025701_HHP012_INT80_G_ueF_FC65.zip:   0%|          | 0/321795336 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e16b7afd82b4d4986e1f85bb4146b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160.zip:   0%|          | 0/321054371 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb700485de74921b4b85b4ec9f05429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1BB_20190616T025659_20190628T025700_HHP012_INT80_G_ueF_9B18.zip:   0%|          | 0/320512433 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only succeeded jobs can be downloaded; job is FAILED. Skipping download for HyP3 INSAR_GAMMA job ba48fbcd-8c9c-4411-a32a-ca4866bd5533.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d418a2f40c4330a4af71371112de09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1AA_20190704T025742_20190716T025743_HHP012_INT80_G_ueF_C638.zip:   0%|          | 0/321491234 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ce62580c6740dabbc23c8a852a71c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1BA_20190616T025659_20190622T025741_HHP006_INT80_G_ueF_1D87.zip:   0%|          | 0/318941036 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6052b9c63274594b9809fe8e238c34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1AB_20190622T025741_20190628T025700_HHP006_INT80_G_ueF_9507.zip:   0%|          | 0/318902542 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95564aded7c4157af9251ac2fb9127c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1AB_20190704T025742_20190710T025701_HHP006_INT80_G_ueF_668F.zip:   0%|          | 0/321173863 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d290a5fde9bd49819dd5fea035e119ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "S1BA_20190710T025701_20190716T025743_HHP006_INT80_G_ueF_BF37.zip:   0%|          | 0/318958869 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "insar_products = jobs.download_files(data_dir)\n",
    "insar_products = [sdk.util.extract_zipped_product(ii) for ii in insar_products]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181031f",
   "metadata": {},
   "source": [
    "## 3. Time-series Analysis with MintPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd1b850",
   "metadata": {},
   "source": [
    "### 3.1 Subset all GeoTIFFs to their common overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a974bcc9-1ddc-48bb-8134-b1dfe0f1fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GDAL==3.4.1\n",
      "  Downloading GDAL-3.4.1.tar.gz (755 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.9/755.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: GDAL\n",
      "  Building wheel for GDAL (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for GDAL: filename=GDAL-3.4.1-cp311-cp311-linux_x86_64.whl size=1062375 sha256=70335e56633acb7b553e9992bea8faa9d5dd15c1c7b4367f08443e74add2aef2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e9/71/fd/44c1a8ffcf965090e76f303dee7ee88bf5c3ec34d5d2803c90\n",
      "Successfully built GDAL\n",
      "Installing collected packages: GDAL\n",
      "Successfully installed GDAL-3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install GDAL==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31f75d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "def get_common_overlap(file_list: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the common overlap of  a list of GeoTIFF files\n",
    "    \n",
    "    Arg:\n",
    "        file_list: a list of GeoTIFF files\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], the upper-left x, upper-left y, lower-right x, and lower-right y\n",
    "         corner coordinates of the common overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in file_list]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43c55f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = data_dir.glob('*/*_dem.tif')\n",
    "\n",
    "overlap = get_common_overlap(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20d94460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "def clip_hyp3_products_to_common_overlap(data_dir: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all GeoTIFF files to their common overlap\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        overlap:\n",
    "            a list of the upper-left x, upper-left y, lower-right-x, and lower-tight y\n",
    "            corner coordinates of the common overlap\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    files_for_mintpy = ['_water_mask.tif', '_corr.tif', '_unw_phase.tif', '_dem.tif', '_lv_theta.tif', '_lv_phi.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "\n",
    "        for file in data_dir.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "023ca045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clip_hyp3_products_to_common_overlap(data_dir, overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be356f",
   "metadata": {},
   "source": [
    "### 3.2 Create the MintPy config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2fb50647-5770-4cdf-b440-2ff05d0e0a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/notebooks/2019_thwaites')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c3cf17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mintpy_config = work_dir / 'mintpy_config.txt'\n",
    "mintpy_config.write_text(\n",
    "f\"\"\"\n",
    "mintpy.load.processor        = hyp3\n",
    "##---------interferogram datasets\n",
    "mintpy.load.unwFile          = {data_dir}/*/*_unw_phase_clipped.tif\n",
    "mintpy.load.corFile          = {data_dir}/*/*_corr_clipped.tif\n",
    "##---------geometry datasets:\n",
    "mintpy.load.demFile          = {data_dir}/*/*_dem_clipped.tif\n",
    "mintpy.load.incAngleFile     = {data_dir}/*/*_lv_theta_clipped.tif\n",
    "mintpy.load.azAngleFile      = {data_dir}/*/*_lv_phi_clipped.tif\n",
    "mintpy.load.waterMaskFile    = {data_dir}/*/*_water_mask_clipped.tif\n",
    "mintpy.troposphericDelay.method = no\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87385631",
   "metadata": {},
   "source": [
    "### 3.3 run MintPy to do the time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a012c642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___________________________________________________________\n",
      "\n",
      "  /##      /## /##             /##     /#######\n",
      " | ###    /###|__/            | ##    | ##__  ##\n",
      " | ####  /#### /## /#######  /######  | ##  \\ ## /##   /##\n",
      " | ## ##/## ##| ##| ##__  ##|_  ##_/  | #######/| ##  | ##\n",
      " | ##  ###| ##| ##| ##  \\ ##  | ##    | ##____/ | ##  | ##\n",
      " | ##\\  # | ##| ##| ##  | ##  | ## /##| ##      | ##  | ##\n",
      " | ## \\/  | ##| ##| ##  | ##  |  ####/| ##      |  #######\n",
      " |__/     |__/|__/|__/  |__/   \\___/  |__/       \\____  ##\n",
      "                                                 /##  | ##\n",
      "                                                |  ######/\n",
      "   Miami InSAR Time-series software in Python    \\______/\n",
      "          MintPy 1.5.3, 2023-11-23\n",
      "___________________________________________________________\n",
      "\n",
      "--RUN-at-2024-02-22 14:01:37.406438--\n",
      "Current directory: /home/jovyan/notebooks\n",
      "Run routine processing with smallbaselineApp.py on steps: ['load_data', 'modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "Remaining steps: ['modify_network', 'reference_point', 'quick_overview', 'correct_unwrap_error', 'invert_network', 'correct_LOD', 'correct_SET', 'correct_troposphere', 'deramp', 'correct_topography', 'residual_RMS', 'reference_date', 'velocity', 'geocode', 'google_earth', 'hdfeos5']\n",
      "--------------------------------------------------\n",
      "Project name: mintpy_config\n",
      "Go to work directory: /home/jovyan/notebooks/2019_thwaites\n",
      "copy default template file /opt/conda/lib/python3.11/site-packages/mintpy/defaults/smallbaselineApp.cfg to work directory\n",
      "read custom template file: /home/jovyan/notebooks/2019_thwaites/mintpy_config.txt\n",
      "update default template based on input custom template\n",
      "    mintpy.load.processor: auto --> hyp3\n",
      "    mintpy.load.unwFile: auto --> /home/jovyan/notebooks/2019_thwaites/data/*/*_unw_phase_clipped.tif\n",
      "    mintpy.load.corFile: auto --> /home/jovyan/notebooks/2019_thwaites/data/*/*_corr_clipped.tif\n",
      "    mintpy.load.demFile: auto --> /home/jovyan/notebooks/2019_thwaites/data/*/*_dem_clipped.tif\n",
      "    mintpy.load.incAngleFile: auto --> /home/jovyan/notebooks/2019_thwaites/data/*/*_lv_theta_clipped.tif\n",
      "    mintpy.load.azAngleFile: auto --> /home/jovyan/notebooks/2019_thwaites/data/*/*_lv_phi_clipped.tif\n",
      "    mintpy.load.waterMaskFile: auto --> /home/jovyan/notebooks/2019_thwaites/data/*/*_water_mask_clipped.tif\n",
      "    mintpy.troposphericDelay.method: auto --> no\n",
      "copy mintpy_config.txt    to inputs   directory for backup.\n",
      "copy smallbaselineApp.cfg to inputs   directory for backup.\n",
      "copy mintpy_config.txt    to pic      directory for backup.\n",
      "copy smallbaselineApp.cfg to pic      directory for backup.\n",
      "read default template file: /home/jovyan/notebooks/2019_thwaites/smallbaselineApp.cfg\n",
      "\n",
      "\n",
      "******************** step - load_data ********************\n",
      "\n",
      "load_data.py --template /home/jovyan/notebooks/2019_thwaites/smallbaselineApp.cfg /home/jovyan/notebooks/2019_thwaites/mintpy_config.txt --project mintpy_config\n",
      "processor : hyp3\n",
      "SAR platform/sensor : unknown from project name \"mintpy_config\"\n",
      "--------------------------------------------------\n",
      "prepare metadata files for hyp3 products\n",
      "prep_hyp3.py \"/home/jovyan/notebooks/2019_thwaites/data/*/*_unw_phase_clipped.tif\"\n",
      "prep_hyp3.py \"/home/jovyan/notebooks/2019_thwaites/data/*/*_corr_clipped.tif\"\n",
      "prep_hyp3.py \"/home/jovyan/notebooks/2019_thwaites/data/*/*_dem_clipped.tif\"\n",
      "prep_hyp3.py \"/home/jovyan/notebooks/2019_thwaites/data/*/*_lv_theta_clipped.tif\"\n",
      "prep_hyp3.py \"/home/jovyan/notebooks/2019_thwaites/data/*/*_lv_phi_clipped.tif\"\n",
      "prep_hyp3.py \"/home/jovyan/notebooks/2019_thwaites/data/*/*_water_mask_clipped.tif\"\n",
      "--------------------------------------------------\n",
      "updateMode : True\n",
      "compression: None\n",
      "multilook x/ystep: 1/1\n",
      "multilook method : nearest\n",
      "--------------------------------------------------\n",
      "searching geometry files info\n",
      "input data files:\n",
      "height          : /home/jovyan/notebooks/2019_thwaites/data/S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160/S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160_dem_clipped.tif\n",
      "incidenceAngle  : /home/jovyan/notebooks/2019_thwaites/data/S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160/S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160_lv_theta_clipped.tif\n",
      "azimuthAngle    : /home/jovyan/notebooks/2019_thwaites/data/S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160/S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160_lv_phi_clipped.tif\n",
      "waterMask       : /home/jovyan/notebooks/2019_thwaites/data/S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160/S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160_water_mask_clipped.tif\n",
      "--------------------------------------------------\n",
      "create HDF5 file /home/jovyan/notebooks/2019_thwaites/inputs/geometryGeo.h5 with w mode\n",
      "create dataset /height             of <class 'numpy.float32'>   in size of (4315, 4259) with compression = lzf\n",
      "create dataset /incidenceAngle     of <class 'numpy.float32'>   in size of (4315, 4259) with compression = lzf\n",
      "    convert incidenceAngle  from Gamma (from horizontal in radian)  to MintPy (from vertical in degree) convention.\n",
      "create dataset /azimuthAngle       of <class 'numpy.float32'>   in size of (4315, 4259) with compression = lzf\n",
      "    convert azimuthAngle    from Gamma (from east in radian)  to MintPy (from north in degree) convention.\n",
      "create dataset /waterMask          of <class 'numpy.bool_'>     in size of (4315, 4259) with compression = lzf\n",
      "prepare slantRangeDistance ...\n",
      "    geocoded input, use incidenceAngle from file: S1AA_20190610T025740_20190622T025741_HHP012_INT80_G_ueF_B160_lv_theta_clipped.tif\n",
      "    convert incidence angle from Gamma to MintPy convention.\n",
      "create dataset /slantRangeDistance of <class 'numpy.float32'>   in size of (4315, 4259) with compression = lzf\n",
      "Finished writing to /home/jovyan/notebooks/2019_thwaites/inputs/geometryGeo.h5\n",
      "--------------------------------------------------\n",
      "searching interferogram pairs info\n",
      "input data files:\n",
      "unwrapPhase     : /home/jovyan/notebooks/2019_thwaites/data/*/*_unw_phase_clipped.tif\n",
      "coherence       : /home/jovyan/notebooks/2019_thwaites/data/*/*_corr_clipped.tif\n",
      "number of unwrapPhase     : 10\n",
      "number of coherence       : 10\n",
      "--------------------------------------------------\n",
      "create HDF5 file /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 with w mode\n",
      "create dataset /unwrapPhase of <class 'numpy.float32'>   in size of (10, 4315, 4259) with compression = None\n",
      "[==================================================] 20190710_20190716    0s /     0s \n",
      "create dataset /coherence   of <class 'numpy.float32'>   in size of (10, 4315, 4259) with compression = None\n",
      "[==================================================] 20190710_20190716    0s /     0s \n",
      "create dataset /date        of <class 'numpy.bytes_'>    in size of (10, 2)\n",
      "create dataset /bperp       of <class 'numpy.float32'>   in size of (10,)\n",
      "create dataset /dropIfgram  of <class 'numpy.bool_'>     in size of (10,)\n",
      "add extra metadata: {'PROJECT_NAME': 'mintpy_config'}\n",
      "Finished writing to /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "searching ionosphere pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['unwrapPhase']! Skip loading for ionosphere stack.\n",
      "--------------------------------------------------\n",
      "searching offset pairs info\n",
      "input data files:\n",
      "WARNING: No data files found for the required dataset: ['rangeOffset', 'azimuthOffset']! Skip loading for offset stack.\n",
      "time used: 00 mins 5.4 secs.\n",
      "\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "Loaded dataset are processed by InSAR software: hyp3\n",
      "Loaded dataset are in GEO coordinates\n",
      "Interferogram Stack: /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5\n",
      "Geometry      File : /home/jovyan/notebooks/2019_thwaites/inputs/geometryGeo.h5\n",
      "Lookup Table  File : None\n",
      "--------------------------------------------------\n",
      "updating metadata based on custom template file mintpy_config.txt for file: ifgramStack.h5\n",
      "\n",
      "\n",
      "******************** step - modify_network ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "generate /home/jovyan/notebooks/2019_thwaites/waterMask.h5 from /home/jovyan/notebooks/2019_thwaites/inputs/geometryGeo.h5 for conveniency\n",
      "create HDF5 file: /home/jovyan/notebooks/2019_thwaites/waterMask.h5 with w mode\n",
      "create dataset /waterMask of bool       in size of (4315, 4259)         with compression=None\n",
      "finished writing to /home/jovyan/notebooks/2019_thwaites/waterMask.h5\n",
      "\n",
      "modify_network.py /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 -t /home/jovyan/notebooks/2019_thwaites/smallbaselineApp.cfg\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "No lookup table (longitude or rangeCoord) found in files.\n",
      "No input option found to remove interferogram\n",
      "Keep all interferograms by enable --reset option\n",
      "--------------------------------------------------\n",
      "reset dataset 'dropIfgram' to True for all interferograms for file: /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5\n",
      "All dropIfgram are already True, no need to reset.\n",
      "\n",
      "plot_network.py /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 -t /home/jovyan/notebooks/2019_thwaites/smallbaselineApp.cfg --nodisplay -d coherence -v 0.2 1.0\n",
      "read options from template file: smallbaselineApp.cfg\n",
      "read temporal/spatial baseline info from file: /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5\n",
      "open ifgramStack file: ifgramStack.h5\n",
      "calculating spatial mean of coherence in file /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 ...\n",
      "read mask from file: waterMask.h5\n",
      "[==================================================] 10/10   0s /     0s \n",
      "write average value in space into text file: coherenceSpatialAvg.txt\n",
      "number of acquisitions: 7\n",
      "number of interferograms: 10\n",
      "shift all perp baseline by -77.50617218017578 to zero mean for plotting\n",
      "--------------------------------------------------\n",
      "number of interferograms marked as drop: 0\n",
      "number of interferograms marked as keep: 10\n",
      "number of acquisitions marked as drop: 0\n",
      "save figure to pbaseHistory.pdf\n",
      "save figure to coherenceMatrix.pdf\n",
      "save figure to coherenceHistory.pdf\n",
      "max perpendicular baseline: 157.36 m\n",
      "max temporal      baseline: 12.0 days\n",
      "showing coherence\n",
      "data range: [0.2119, 0.5145]\n",
      "display range: [0.2, 1.0]\n",
      "save figure to network.pdf\n",
      "\n",
      "\n",
      "******************** step - reference_point ********************\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "generate_mask.py /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 --nonzero -o /home/jovyan/notebooks/2019_thwaites/maskConnComp.h5 --update\n",
      "input ifgramStack file: /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /home/jovyan/notebooks/2019_thwaites/maskConnComp.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the common mask of pixels with non-zero unwrapPhase value\n",
      "[==================================================] 10/10   0s /     0s \n",
      "create HDF5 file: /home/jovyan/notebooks/2019_thwaites/maskConnComp.h5 with w mode\n",
      "create dataset /mask of bool       in size of (4315, 4259)         with compression=None\n",
      "finished writing to /home/jovyan/notebooks/2019_thwaites/maskConnComp.h5\n",
      "time used: 00 mins 0.8 secs.\n",
      "\n",
      "temporal_average.py /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 --dataset coherence -o /home/jovyan/notebooks/2019_thwaites/avgSpatialCoh.h5 --update\n",
      "--------------------------------------------------\n",
      "update mode: ON\n",
      "1) output file /home/jovyan/notebooks/2019_thwaites/avgSpatialCoh.h5 NOT exist.\n",
      "run or skip: run.\n",
      "calculate the temporal average of coherence in file /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 4315/4315 \n",
      "create HDF5 file: /home/jovyan/notebooks/2019_thwaites/avgSpatialCoh.h5 with w mode\n",
      "create dataset /coherence of float32    in size of (4315, 4259)         with compression=None\n",
      "finished writing to /home/jovyan/notebooks/2019_thwaites/avgSpatialCoh.h5\n",
      "time used: 00 mins 2.4 secs\n",
      "\n",
      "Input data seems to be geocoded. Lookup file not needed.\n",
      "\n",
      "reference_point.py /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 -t /home/jovyan/notebooks/2019_thwaites/smallbaselineApp.cfg -c /home/jovyan/notebooks/2019_thwaites/avgSpatialCoh.h5\n",
      "--------------------------------------------------\n",
      "reading reference info from template: /home/jovyan/notebooks/2019_thwaites/smallbaselineApp.cfg\n",
      "no input reference y/x.\n",
      "reference point selection method: maxCoherence\n",
      "--------------------------------------------------\n",
      "calculate the temporal average of unwrapPhase in file /home/jovyan/notebooks/2019_thwaites/inputs/ifgramStack.h5 ...\n",
      "[==================================================] lines 4315/4315 \n",
      "random select pixel with coherence > 0.85\n",
      "\tbased on coherence file: avgSpatialCoh.h5\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/smallbaselineApp.py\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/mintpy/cli/smallbaselineApp.py\", line 208, in main\n",
      "    run_smallbaselineApp(inps)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/mintpy/smallbaselineApp.py\", line 1117, in run_smallbaselineApp\n",
      "    app.run(steps=inps.runSteps)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/mintpy/smallbaselineApp.py\", line 880, in run\n",
      "    self.run_reference_point(sname)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/mintpy/smallbaselineApp.py\", line 306, in run_reference_point\n",
      "    mintpy.cli.reference_point.main(iargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/mintpy/cli/reference_point.py\", line 144, in main\n",
      "    reference_file(inps)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/mintpy/reference_point.py\", line 61, in reference_file\n",
      "    inps.ref_y, inps.ref_x = select_max_coherence_yx(\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/mintpy/reference_point.py\", line 240, in select_max_coherence_yx\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: No pixel with average spatial coherence > 0.85 are found for automatic reference point selection!\n",
      "Try the following:\n",
      "  1) manually specify the reference point using mintpy.reference.yx/lalo option.\n",
      "  2) change mintpy.reference.minCoherence to a lower value.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!smallbaselineApp.py --dir {work_dir} {mintpy_config}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e866ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib widget\n",
    "from mintpy.cli import view, tsview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed9af8e8-37b0-4d74-9c21-c73b6ddd39df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/notebooks/2019_thwaites')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acf5cfdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Not a datatype (not a datatype)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mview\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mwork_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/velocity.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/mintpy/cli/view.py:173\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(iargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(iargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# parse\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     inps \u001b[38;5;241m=\u001b[39m \u001b[43mcmd_line_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43miargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# import\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmintpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mview\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m viewer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/mintpy/cli/view.py:104\u001b[0m, in \u001b[0;36mcmd_line_parse\u001b[0;34m(iargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m inps \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args(args\u001b[38;5;241m=\u001b[39miargs)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# import\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmintpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ptime, readfile\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# save argv (to check the manually specified arguments)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# use iargs        for python call\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# use sys.argv[1:] for command line call\u001b[39;00m\n\u001b[1;32m    109\u001b[0m inps\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m iargs \u001b[38;5;28;01mif\u001b[39;00m iargs \u001b[38;5;28;01melse\u001b[39;00m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/mintpy/utils/ptime.py:16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmintpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprogress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m progressBar\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m################################################################\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_compact_isoformat\u001b[39m(date_str):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/mintpy/objects/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mramp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/mintpy/objects/giant.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime \u001b[38;5;28;01mas\u001b[39;00m dt\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m GIANT_DSET_NAMES \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecons\u001b[39m\u001b[38;5;124m'\u001b[39m,        \u001b[38;5;66;03m#Reconstructed filtered time-series in mm\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrawts\u001b[39m\u001b[38;5;124m'\u001b[39m,         \u001b[38;5;66;03m#Raw time-series in mm\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msar_aps\u001b[39m\u001b[38;5;124m'\u001b[39m,       \u001b[38;5;66;03m#Atmospheric phase screen for each of the SAR scenes in mm\u001b[39;00m\n\u001b[1;32m     25\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/h5py/__init__.py:45\u001b[0m\n\u001b[1;32m     36\u001b[0m     _warn((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5py is running against HDF5 \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m when it was built against \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis may cause problems\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_version_tuple),\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_built_version_tuple)\n\u001b[1;32m     40\u001b[0m     ))\n\u001b[1;32m     43\u001b[0m _errors\u001b[38;5;241m.\u001b[39msilence_errors()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_converters \u001b[38;5;28;01mas\u001b[39;00m _register_converters, \\\n\u001b[1;32m     46\u001b[0m                    unregister_converters \u001b[38;5;28;01mas\u001b[39;00m _unregister_converters\n\u001b[1;32m     47\u001b[0m _register_converters()\n\u001b[1;32m     48\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(_unregister_converters)\n",
      "File \u001b[0;32mh5py/_conv.pyx:1\u001b[0m, in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5r.pyx:1\u001b[0m, in \u001b[0;36minit h5py.h5r\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5p.pyx:1\u001b[0m, in \u001b[0;36minit h5py.h5p\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:146\u001b[0m, in \u001b[0;36minit h5py.h5t\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:80\u001b[0m, in \u001b[0;36mh5py.h5t.lockid\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:49\u001b[0m, in \u001b[0;36mh5py.h5t.typewrap\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Not a datatype (not a datatype)"
     ]
    }
   ],
   "source": [
    "\n",
    "view.main([f'{work_dir}/velocity.h5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6172aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tsview.main([f'{work_dir}/timeseries.h5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a858c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
